# =============================================================================
# FAIRiAgent Evaluation Configuration Template
# =============================================================================
# Copy to env.evaluation (or .env in evaluation context) and fill in credentials.
# Do not commit files containing API keys.
# This is the only template: evaluation settings + FAIRiAgent model (which LLM to run).

# =============================================================================
# LangSmith (Optional but recommended for evaluation runs)
# =============================================================================
LANGSMITH_API_KEY=your_langsmith_key_here
LANGSMITH_PROJECT=fairifier-evaluation
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
# LANGSMITH_USE_FAIR_NAMING=true

# =============================================================================
# FAIRiAgent model (LLM used when running FAIRiAgent in evaluation)
# =============================================================================
# ollama | openai | qwen | anthropic
LLM_PROVIDER=qwen
# Model name, e.g. qwen3-max-2026-01-23, gpt-4o, qwen-flash, llama3.1:70b
FAIRIFIER_LLM_MODEL=qwen3-max-2026-01-23
# Required for openai/qwen/anthropic; leave empty for ollama
LLM_API_KEY=your_api_key_here
# Provider base URL (optional): QWEN_API_BASE_URL, OPENAI_API_BASE_URL, FAIRIFIER_LLM_BASE_URL
# QWEN_API_BASE_URL=https://dashscope-intl.aliyuncs.com/compatible-mode/v1
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=100000
LLM_ENABLE_THINKING=false

# Processing & Critic (optional; same across runs for control)
FAIRIFIER_MAX_DOCUMENT_SIZE_MB=50
FAIRIFIER_MAX_PROCESSING_TIME_MINUTES=10
FAIRIFIER_MIN_CONFIDENCE_THRESHOLD=0.75
FAIRIFIER_MAX_STEP_RETRIES=2
FAIRIFIER_MAX_GLOBAL_RETRIES=5
FAIRIFIER_CRITIC_ACCEPT_THRESHOLD_DOCUMENT_PARSER=0.75
FAIRIFIER_CRITIC_ACCEPT_THRESHOLD_KNOWLEDGE_RETRIEVER=0.7
FAIRIFIER_CRITIC_ACCEPT_THRESHOLD_JSON_GENERATOR=0.75
FAIRIFIER_CRITIC_ACCEPT_THRESHOLD_GENERAL=0.7
FAIRIFIER_CRITIC_RETRY_MIN_THRESHOLD=0.4
FAIRIFIER_CRITIC_RETRY_MAX_THRESHOLD=0.69

# MinerU (optional)
MINERU_ENABLED=true
MINERU_SERVER_URL=http://localhost:30000
MINERU_CLI_PATH=mineru
MINERU_BACKEND=vlm-http-client
MINERU_TIMEOUT_SECONDS=300

# =============================================================================
# Evaluation Paths & Workers
# =============================================================================
EVAL_GROUND_TRUTH_PATH=evaluation/datasets/annotated/ground_truth_v1.json
EVAL_OUTPUT_DIR=evaluation/runs
EVAL_NUM_WORKERS=2

# =============================================================================
# LLM-as-Judge (evaluation of FAIRiAgent outputs)
# =============================================================================
# Provider: anthropic, openai, ollama
EVAL_JUDGE_PROVIDER=anthropic
EVAL_JUDGE_MODEL=claude-sonnet-4
EVAL_JUDGE_API_KEY=your_anthropic_key_here
EVAL_JUDGE_TEMPERATURE=0.0
EVAL_JUDGE_MAX_TOKENS=16384
# EVAL_JUDGE_BASE_URL=  (if needed for custom endpoint)

# =============================================================================
# FAIR Data Station (Optional)
# =============================================================================
FAIR_DS_API_URL=http://localhost:8083

# =============================================================================
# Evaluators & Features
# =============================================================================
# Comma-separated: completeness, correctness, schema, ontology, llm_judge (empty = all)
EVAL_RUN_EVALUATORS=
EVAL_ENABLE_ONTOLOGY_VALIDATION=true
EVAL_ENABLE_SCHEMA_VALIDATION=true
EVAL_COMPUTE_CORRELATIONS=true

# =============================================================================
# Statistical Analysis (Optional)
# =============================================================================
EVAL_CONFIDENCE_LEVEL=0.95
EVAL_MIN_SAMPLES_FOR_STATS=10
