# Ollama Local Model Configuration for Evaluation

# ============================================
# LLM Provider Configuration
# ============================================
LLM_PROVIDER=ollama
FAIRIFIER_LLM_MODEL=llama3.1:70b
FAIRIFIER_LLM_BASE_URL=http://localhost:11434
LLM_API_KEY=  # Not required for Ollama
LLM_TEMPERATURE=0.5
LLM_MAX_TOKENS=100000
LLM_ENABLE_THINKING=false

# ============================================
# LangSmith Tracking (Model-specific project)
# ============================================
LANGSMITH_API_KEY=your_langsmith_key_here
LANGSMITH_PROJECT=fairifier-eval-ollama-llama3.1-70b
LANGSMITH_ENDPOINT=https://api.smith.langchain.com

# ============================================
# FAIRiAgent Configuration
# ============================================
# Retry settings
FAIRIFIER_MAX_STEP_RETRIES=3
FAIRIFIER_MAX_GLOBAL_RETRIES=10

# Critic thresholds
FAIRIFIER_CRITIC_ACCEPT_THRESHOLD_DOCUMENT_PARSER=0.7
FAIRIFIER_CRITIC_ACCEPT_THRESHOLD_KNOWLEDGE_RETRIEVER=0.7
FAIRIFIER_CRITIC_ACCEPT_THRESHOLD_JSON_GENERATOR=0.75

# Confidence weights
FAIRIFIER_CONF_WEIGHT_CRITIC=0.4
FAIRIFIER_CONF_WEIGHT_STRUCTURAL=0.3
FAIRIFIER_CONF_WEIGHT_VALIDATION=0.3

# FAIR Data Station
FAIR_DS_API_URL=http://localhost:8083

# MinerU (if enabled)
FAIRIFIER_MINERU_ENABLED=false
FAIRIFIER_MINERU_SERVER_URL=http://localhost:8080

