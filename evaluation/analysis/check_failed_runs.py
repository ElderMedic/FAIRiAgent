#!/usr/bin/env python3
"""æ£€æŸ¥å¤±è´¥çš„è¿è¡Œå¹¶ç»Ÿè®¡éœ€è¦è¡¥è·‘çš„æ•°é‡ï¼ˆæ’é™¤ JSON è§£æé”™è¯¯ï¼‰"""

import json
from pathlib import Path
from collections import defaultdict

# é…ç½®
RUNS_DIR = Path(__file__).parent.parent / "runs"
EXPECTED_REPEATS = 10  # æ¯ä¸ªæ¨¡å‹æ¯ä¸ªæ–‡æ¡£åº”è¯¥è·‘10æ¬¡
DOCS = ["earthworm", "biosensor"]  # biorem æš‚æ—¶ç§»é™¤

# æ˜¯å¦æ’é™¤ JSON è§£æé”™è¯¯ï¼ˆè¿™äº›æ˜¯ LLM è¾“å‡ºé—®é¢˜ï¼Œä¸æ˜¯ workflow æœªå®Œæˆï¼‰
EXCLUDE_JSON_PARSING_ERRORS = True

def check_run_failure(run_dir: Path) -> tuple[bool, str]:
    """æ£€æŸ¥è¿è¡Œæ˜¯å¦æˆåŠŸï¼Œè¿”å› (is_success, error_type)"""
    metadata_file = run_dir / "metadata_json.json"
    eval_result_file = run_dir / "eval_result.json"
    
    # å¦‚æœæœ‰ metadata_json.jsonï¼Œè¯´æ˜æˆåŠŸ
    if metadata_file.exists():
        return True, ""
    
    # æ£€æŸ¥å¤±è´¥åŸå› 
    if eval_result_file.exists():
        try:
            with open(eval_result_file, 'r') as f:
                result = json.load(f)
                error = result.get('error', '')
                
                if 'timed out' in error.lower():
                    return False, 'timeout'
                elif 'not found after workflow' in error.lower():
                    return False, 'metadata_not_found'
                elif 'json parsing' in error.lower():
                    return False, 'json_parsing_error'
                else:
                    return False, 'other_error'
        except:
            return False, 'eval_result_parse_error'
    
    return False, 'no_eval_result'

def main():
    results = defaultdict(lambda: defaultdict(lambda: {
        'total': 0,
        'success': 0,
        'failed': 0,
        'timeout': 0,
        'metadata_not_found': 0,
        'json_parsing_error': 0,
        'other_error': 0,
        'no_eval_result': 0,
        'eval_result_parse_error': 0
    }))
    
    # éå†æ‰€æœ‰è¿è¡Œç›®å½•
    for run_batch_dir in RUNS_DIR.iterdir():
        if not run_batch_dir.is_dir() or run_batch_dir.name == 'archive':
            continue
        
        # éå†æ¨¡å‹ç›®å½•
        for model_dir in run_batch_dir.iterdir():
            if not model_dir.is_dir():
                continue
            
            outputs_dir = model_dir / "outputs"
            if not outputs_dir.exists():
                continue
            
            # éå†æ¨¡å‹è¾“å‡ºå­ç›®å½•
            for output_subdir in outputs_dir.iterdir():
                if not output_subdir.is_dir():
                    continue
                
                model_name = output_subdir.name
                
                # éå†æ–‡æ¡£
                for doc in DOCS:
                    doc_dir = output_subdir / doc
                    if not doc_dir.exists():
                        continue
                    
                    # æ£€æŸ¥æ‰€æœ‰ run_* ç›®å½•
                    run_dirs = sorted([d for d in doc_dir.iterdir() if d.is_dir() and d.name.startswith('run_')])
                    
                    for run_dir in run_dirs:
                        results[model_name][doc]['total'] += 1
                        
                        is_success, error_type = check_run_failure(run_dir)
                        
                        if is_success:
                            results[model_name][doc]['success'] += 1
                        else:
                            # å¦‚æœæ’é™¤ JSON è§£æé”™è¯¯ï¼Œè·³è¿‡è¿™ç±»é”™è¯¯
                            if EXCLUDE_JSON_PARSING_ERRORS and error_type == 'json_parsing_error':
                                # è§†ä¸º"ä¸éœ€è¦é‡è·‘"ï¼Œä½†ä»è®°å½•ä¸ºå¤±è´¥
                                results[model_name][doc]['failed'] += 1
                                results[model_name][doc][error_type] += 1
                            else:
                                results[model_name][doc]['failed'] += 1
                                if error_type:
                                    results[model_name][doc][error_type] += 1
    
    # æ‰“å°ç»“æœ
    print("\n" + "="*80)
    print("å¤±è´¥è¿è¡Œç»Ÿè®¡ä¸è¡¥è·‘éœ€æ±‚")
    if EXCLUDE_JSON_PARSING_ERRORS:
        print("ï¼ˆå·²æ’é™¤ JSON è§£æé”™è¯¯ - è¿™äº›æ˜¯ LLM è¾“å‡ºé—®é¢˜ï¼Œä¸éœ€è¦é‡è·‘ï¼‰")
    print("="*80 + "\n")
    
    total_to_rerun = 0
    rerun_details = []
    
    for model_name in sorted(results.keys()):
        print(f"\n### {model_name.upper()}")
        print("-" * 80)
        
        for doc in DOCS:
            if doc not in results[model_name]:
                continue
            
            stats = results[model_name][doc]
            success = stats['success']
            failed = stats['failed']
            
            # è®¡ç®—éœ€è¦è¡¥è·‘çš„æ¬¡æ•°ï¼ˆæ’é™¤ JSON è§£æé”™è¯¯ï¼‰
            if EXCLUDE_JSON_PARSING_ERRORS:
                # ä¸ç®— JSON è§£æé”™è¯¯ï¼Œè¿™äº›ä¸éœ€è¦é‡è·‘
                json_errors = stats['json_parsing_error']
                # å®é™…éœ€è¦è¡¥çš„ = æœŸæœ›æ¬¡æ•° - æˆåŠŸæ¬¡æ•°
                # ä½†ä¸åŒ…æ‹¬ JSON è§£æé”™è¯¯ï¼ˆè¿™äº›ç®—ä½œ"æˆåŠŸ"è¿è¡Œï¼Œåªæ˜¯ LLM è¾“å‡ºé—®é¢˜ï¼‰
                needed = max(0, EXPECTED_REPEATS - (success + json_errors))
            else:
                needed = max(0, EXPECTED_REPEATS - success)
            
            print(f"\n  {doc}:")
            print(f"    âœ… æˆåŠŸ: {success}/{EXPECTED_REPEATS}")
            print(f"    âŒ å¤±è´¥: {failed}")
            
            if failed > 0:
                print(f"    å¤±è´¥åŸå› :")
                if stats['timeout'] > 0:
                    print(f"      - Timeout: {stats['timeout']}")
                if stats['metadata_not_found'] > 0:
                    print(f"      - Metadataæœªæ‰¾åˆ°: {stats['metadata_not_found']}")
                if stats['json_parsing_error'] > 0:
                    print(f"      - JSONè§£æé”™è¯¯: {stats['json_parsing_error']}")
                if stats['other_error'] > 0:
                    print(f"      - å…¶ä»–é”™è¯¯: {stats['other_error']}")
            
            if needed > 0:
                print(f"    ğŸ”„ éœ€è¦è¡¥è·‘: {needed} æ¬¡")
                total_to_rerun += needed
                rerun_details.append({
                    'model': model_name,
                    'doc': doc,
                    'needed': needed,
                    'success': success,
                    'failed': failed
                })
    
    # æ€»ç»“
    print("\n" + "="*80)
    print("è¡¥è·‘æ€»ç»“")
    print("="*80 + "\n")
    
    if total_to_rerun > 0:
        print(f"**æ€»è®¡éœ€è¦è¡¥è·‘: {total_to_rerun} æ¬¡**\n")
        
        # æŒ‰æ¨¡å‹åˆ†ç»„
        model_summary = defaultdict(int)
        for item in rerun_details:
            model_summary[item['model']] += item['needed']
        
        print("æŒ‰æ¨¡å‹åˆ†ç»„:")
        for model_name, count in sorted(model_summary.items()):
            print(f"  - {model_name}: {count} æ¬¡")
        
        print("\nè¯¦ç»†åˆ—è¡¨:")
        for item in rerun_details:
            print(f"  - {item['model']} / {item['doc']}: è¡¥è·‘ {item['needed']} æ¬¡ (å·²æœ‰ {item['success']} æ¬¡æˆåŠŸ)")
    else:
        print("âœ… æ‰€æœ‰è¿è¡Œéƒ½å·²å®Œæˆï¼")

if __name__ == "__main__":
    main()

