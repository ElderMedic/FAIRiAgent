# FAIRiAgent - FAIR Metadata Generation Framework

ğŸ§¬ **CLI-first, JSON-only FAIR metadata generation with FAIR-DS compatibility**

## ğŸ¯ Overview

FAIRiAgent is a CLI-first multi-agent framework that automatically extracts information from research documents (PDF/text) and generates **FAIR-DS compatible JSON metadata**. Built with LangGraph and LangChain, it focuses on simplicity, standards compliance, and evidence-based metadata generation.

## âœ¨ Key Features

- ğŸ¤– **Multi-Agent Architecture**: Specialized agents for document parsing, knowledge retrieval, and JSON generation
- ğŸ“„ **Document Processing**: Extract metadata from PDF and text documents
- ğŸ§  **Knowledge Retrieval**: Integrate with FAIR Data Station and local knowledge base
- ğŸ·ï¸ **Evidence-based Fields**: Every field includes evidence, confidence, origin, and package source
- ğŸ“Š **JSON-only Output**: FAIR-DS compatible metadata format (no RDF/RO-Crate)
- ğŸ“ **JSON Line Logging**: Structured logging for debugging and monitoring
- ğŸ”§ **Local Provisional Support**: Extend with local terms (source=local, status=provisional)
- ğŸ›ï¸ **Multi-Model Support**: Ollama (local) / OpenAI / Qwen / Anthropic
- ğŸ” **LangSmith Integration**: Complete tracing and debugging support (é»˜è®¤å¯ç”¨)
- ğŸ¨ **Streamlit Web UI**: Interactive web interface with real-time streaming output
- ğŸ’¬ **Chat-like Streaming**: Real-time LLM response streaming with chat bubble interface
- âš™ï¸ **Configuration Management**: Save and manage runtime configurations
- ğŸ“‹ **Runtime Config Export**: Automatic export of input, .env, and runtime configurations

## ğŸ—ï¸ Architecture

The system uses a LangGraph-based multi-agent workflow:

```
Document â†’ Parse â†’ Plan â†’ Retrieve Knowledge â†’ Generate JSON â†’ Evaluate â†’ Output
```

**Agents:**
1. **Document Parser**: Extracts structured information from documents
2. **Orchestrator**: Plans workflow strategy based on document content
3. **Knowledge Retriever**: Enriches metadata with FAIR-DS and local knowledge
4. **JSON Generator**: Creates FAIR-DS compatible metadata
5. **Critic**: Evaluates quality and provides feedback for retry/escalation

**Workflow Features:**
- ğŸ”„ **Retry Logic**: Automatic retry with feedback from Critic agent
- ğŸ¯ **Conditional Routing**: Dynamic workflow based on evaluation results
- ğŸ“Š **Execution Summary**: Track steps, retries, and outcomes
- ğŸ’¾ **State Persistence**: LangGraph checkpointer for state management

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone <repository-url>
cd FAIRiAgent

# Install dependencies
pip install -r requirements.txt
```

### Basic Usage

**CLI Mode:**
```bash
# Process a document
python run_fairifier.py process your_document.pdf

# Specify output directory
python run_fairifier.py process document.txt --output-dir results/

# Check configuration
python run_fairifier.py config-info
```

**Web UI Mode:**
```bash
# Start Streamlit web interface
python run_fairifier.py ui

# Access at http://localhost:8501
```

**LangGraph Studio (Development):**
```bash
# Start LangGraph dev server
langgraph dev

# Access LangGraph Studio at http://localhost:8123
```

### Configuration

**Environment Variables (.env file):**
```bash
# LLM Provider (Ollama/OpenAI/Qwen/Anthropic)
LLM_PROVIDER=ollama  # or "openai", "qwen", or "anthropic"
FAIRIFIER_LLM_MODEL=llama3  # Model name
FAIRIFIER_LLM_BASE_URL=http://localhost:11434  # For Ollama
LLM_API_KEY=your_key  # For OpenAI/Qwen/Anthropic
LLM_TEMPERATURE=0.5
LLM_MAX_TOKENS=100000
LLM_ENABLE_THINKING=false  # For Qwen models

# FAIR Data Station (optional)
FAIR_DS_API_URL=http://localhost:8083

# LangSmith (optional)
LANGSMITH_API_KEY=your_key
LANGSMITH_PROJECT=fairifier-testing
```

**Web UI Configuration:**
- Access the "âš™ï¸ Configuration" tab in the Streamlit UI
- Configure LLM, LangSmith, and FAIR-DS settings
- Save to session or export to .env file
- Changes apply to next processing run

### Output Files

FAIRiAgent generates (in `output/<project_id>/`):
1. **`metadata_json.json`** - FAIR-DS compatible metadata
2. **`processing_log.jsonl`** - JSON line logs
3. **`llm_responses.json`** - All LLM API interactions
4. **`runtime_config.json`** - Complete runtime configuration including:
   - Input document path
   - Environment variables (.env)
   - LLM configuration
   - Runtime settings
   - Project metadata
5. **`validation_report.txt`** - Validation results (optional)

## ğŸ“Š Output Format

### FAIR-DS Compatible JSON

```json
{
  "fairifier_version": "0.2.0",
  "generated_at": "2025-01-27T10:30:00",
  "document_source": "paper.pdf",
  "overall_confidence": 0.85,
  
  "metadata": [
    {
      "field_name": "project_name",
      "value": "Soil Metagenomics Study",
      "evidence": "Extracted from document title",
      "confidence": 0.95,
      "origin": "document_parser",
      "package_source": "MIMAG",
      "status": "confirmed"
    },
    {
      "field_name": "investigation_type",
      "value": "metagenome",
      "evidence": "Inferred from research domain",
      "confidence": 0.80,
      "origin": "document_parser",
      "package_source": "MIMAG",
      "status": "provisional"
    }
  ],
  
  "statistics": {
    "total_fields": 15,
    "confirmed_fields": 8,
    "provisional_fields": 7
  }
}
```

### JSON Line Logging

```json
{"timestamp": "2025-01-27T10:30:00", "level": "info", "event": "processing_started", "document_path": "paper.pdf"}
{"timestamp": "2025-01-27T10:30:05", "level": "info", "event": "field_extracted", "field_name": "project_name", "confidence": 0.95}
{"timestamp": "2025-01-27T10:30:10", "level": "info", "event": "processing_completed", "status": "completed"}
```

## ğŸ§¬ FAIR Data Station Integration

When connected to a FAIR Data Station instance, FAIRiAgent can:

- ğŸ” Search for standardized terms relevant to your research
- ğŸ“¦ Use community-approved metadata packages
- ğŸ·ï¸ Enhance fields with validated definitions
- ğŸŒ Ensure better interoperability

### Setup FAIR Data Station

```bash
# Download and start FAIR Data Station
wget http://download.systemsbiology.nl/unlock/fairds-latest.jar
java -jar fairds-latest.jar

# Access at http://localhost:8083
```

## ğŸ”§ Local Provisional Extensions

Add custom terms not in FAIR-DS:

```python
from fairifier.services.local_knowledge import initialize_local_kb, LocalTerm
from pathlib import Path

# Initialize local knowledge base
local_kb = initialize_local_kb(Path("kb"))

# Add custom term
local_kb.add_term(LocalTerm(
    name="custom_field",
    label="Custom Field",
    description="Project-specific metadata field",
    source="local",
    status="provisional",
    confidence=0.7
))
```

Local terms are automatically included with `source=local` and `status=provisional`.

## ğŸ“ Project Structure

```
fairifier/
â”œâ”€â”€ agents/              # Multi-agent implementations
â”‚   â”œâ”€â”€ document_parser.py
â”‚   â”œâ”€â”€ knowledge_retriever.py
â”‚   â”œâ”€â”€ json_generator.py
â”‚   â”œâ”€â”€ critic.py
â”‚   â””â”€â”€ orchestrator.py
â”œâ”€â”€ graph/               # LangGraph workflow
â”‚   â”œâ”€â”€ langgraph_app.py # Main LangGraph application
â”‚   â””â”€â”€ __dev__.py       # LangGraph Studio entry point
â”œâ”€â”€ apps/                # Web UI and API
â”‚   â”œâ”€â”€ ui/
â”‚   â”‚   â””â”€â”€ streamlit_app.py  # Streamlit web interface
â”‚   â””â”€â”€ api/             # FastAPI (optional)
â”œâ”€â”€ services/            # FAIR-DS and local knowledge
â”œâ”€â”€ utils/               # Utilities
â”‚   â”œâ”€â”€ llm_helper.py    # LLM interaction utilities
â”‚   â”œâ”€â”€ config_saver.py # Runtime config export
â”‚   â””â”€â”€ json_logger.py  # JSON logging
â”œâ”€â”€ cli.py               # Command-line interface
â”œâ”€â”€ config.py            # Configuration management
â””â”€â”€ models.py            # Data models

kb/                      # Knowledge base
â”œâ”€â”€ local_terms.json     # Local provisional terms
â”œâ”€â”€ local_packages.json  # Local packages
â””â”€â”€ ontologies.json      # Ontology mappings

output/                  # Generated outputs
â””â”€â”€ <project_id>/
    â”œâ”€â”€ metadata_json.json
    â”œâ”€â”€ processing_log.jsonl
    â”œâ”€â”€ llm_responses.json
    â””â”€â”€ runtime_config.json

examples/                # Sample documents
docs/                    # Documentation
langgraph.json           # LangGraph Studio config
```

## ğŸ“ˆ Quality Metrics

FAIRiAgent provides confidence scoring based on:

- âœ… **Document extraction quality** (title, abstract, authors)
- âœ… **Field completion rate** (how many fields have values)
- âœ… **Research domain identification** accuracy
- âœ… **Evidence quality** (how well fields are supported)

Confidence levels:
- **> 0.8**: High confidence, ready to use
- **0.5-0.8**: Good, may need minor review
- **< 0.5**: Requires manual review

## ğŸ› ï¸ Dependencies

Core dependencies:
- `langgraph`: Multi-agent workflow orchestration
- `langchain`: Agent framework and tools
- `langsmith`: Tracing and debugging
- `rdflib`: RDF processing (minimal use)
- `PyMuPDF`: PDF document processing
- `click`: CLI framework

## ğŸ“‹ CLI Commands

```bash
# Process document
python run_fairifier.py process <document> [options]

# Start web UI
python run_fairifier.py ui

# Check status
python run_fairifier.py status <project-id>

# Show configuration
python run_fairifier.py config-info

# Validate document
python run_fairifier.py validate-document <document>
```

**Options:**
- `--output-dir, -o`: Specify output directory
- `--project-id, -p`: Custom project ID
- `--env-file, -e`: Use custom .env file
- `--json-log`: Enable JSON line logging (default: True)
- `--verbose, -v`: Show detailed processing steps

## ğŸ¨ Web UI Features

The Streamlit web interface provides:

- ğŸ“„ **Document Upload**: Drag-and-drop or use example files
- ğŸ’¬ **Real-time Streaming**: Chat-like interface showing LLM responses as they're generated
- ğŸ“Š **Live Logs**: Real-time processing logs and error display
- âš™ï¸ **Configuration Management**: Configure LLM, LangSmith, and FAIR-DS settings
- ğŸ” **Result Review**: View and download generated metadata
- ğŸ“‹ **LLM API Logs**: View all LLM interactions in formatted display

**Access the UI:**
```bash
python run_fairifier.py ui
```

Then open http://localhost:8501 in your browser.

## ğŸ§ª Testing

Test with the provided sample documents:

```bash
# Test basic functionality (CLI)
python run_fairifier.py process examples/inputs/earthworm_4n_paper_bioRXiv.pdf

# Test with all features
python run_fairifier.py process examples/inputs/earthworm_4n_paper_bioRXiv.pdf --fair-ds-url http://localhost:8083

# Test web UI
python run_fairifier.py ui
# Then use the example file option in the UI
```

**Example Files:**
- `examples/inputs/earthworm_4n_paper_bioRXiv.pdf` - Research paper example

### LangSmith Integration

FAIRiAgent includes comprehensive LangSmith integration for debugging and monitoring:

```bash
# Set up LangSmith (get API key from https://smith.langchain.com/)
export LANGSMITH_API_KEY="your_api_key_here"
export LANGSMITH_PROJECT="fairifier-testing"

# Or configure in Streamlit UI under "âš™ï¸ Configuration" tab
```

LangSmith provides:
- ğŸ” **Trace Visualization**: Complete workflow execution flow
- ğŸ“Š **Performance Metrics**: Token usage, costs, and timing
- ğŸ› **Debug Tools**: Step-by-step debugging and error analysis
- ğŸ“ˆ **Monitoring**: Track performance over time
- ğŸ”— **Trace Links**: Direct links to traces from Streamlit UI

**LangGraph Studio Integration:**
```bash
# Start LangGraph dev server
langgraph dev

# Access LangGraph Studio at http://localhost:8123
# Visualize and debug the workflow graph
```

See [LangGraph Studio Setup](docs/guides/LANGGRAPH_STUDIO_SETUP.md) and [LangSmith Testing Guide](docs/LANGSMITH_TESTING_GUIDE.md) for detailed instructions.

## ğŸ“š Documentation

- **Core**
  - [Project Summary](docs/PROJECT_SUMMARY.md) â€“ End-to-end overview
  - [Design Document](docs/DESIGN.md) â€“ System design and architecture
  - [LLM Integration Guide](docs/LLM_INTEGRATION_GUIDE.md) â€“ Provider configuration
  - [LangSmith Testing Guide](docs/LANGSMITH_TESTING_GUIDE.md) â€“ Testing and debugging
- **Guides**
  - [LangGraph Studio Setup](docs/guides/LANGGRAPH_STUDIO_SETUP.md) â€“ Local LangGraph + Studio
  - [Quick Start (ä¸­æ–‡)](docs/guides/QUICKSTART_CN.md) â€“ æœ€ç®€è¿è¡Œæ­¥éª¤
  - [Test Guide](docs/guides/TEST_GUIDE.md) â€“ ç¯å¢ƒéªŒè¯ä¸æµ‹è¯•æµç¨‹
- **Development Notes**
  - [System Ready Checklist](docs/development/SYSTEM_READY.md) â€“ å…¨é¢ç‰¹æ€§éªŒè¯
  - [Workflow Summary](docs/development/WORKFLOW_SUMMARY.md) â€“ å½“å‰å·¥ä½œæµè¯´æ˜
  - [FAIR-DS API Exploration](docs/development/FAIRDS_API_EXPLORATION.md) â€“ API ç»“æ„è°ƒç ”
  - [Implementation Notes](docs/development/README_IMPLEMENTATION.md) â€“ å†å²å®ç°è®°å½•
- **Web UI**
  - [Web UI Guide](fairifier/apps/README.md) â€“ Streamlit UI features and usage

## ğŸ¤ Contributing

This is a research tool designed for:
- Scientific metadata standardization
- FAIR data principles implementation
- Multi-agent system research
- Agentic RAG development

## ğŸ“„ License

MIT License - Free for academic and research use.

---

**ğŸ¯ FAIRiAgent v0.3 - LangGraph-powered, Web UI-enabled, Standards-compliant Metadata Generation**

---

## ğŸ”„ Recent Updates (v0.3)

- âœ… **LangGraph Integration**: Full LangGraph workflow with state persistence
- âœ… **Streamlit Web UI**: Interactive web interface with real-time streaming
- âœ… **Chat-like Streaming**: Real-time LLM response display with chat bubbles
- âœ… **Configuration Management**: Web-based configuration with .env export
- âœ… **Runtime Config Export**: Automatic export of all runtime configurations
- âœ… **Multi-Provider Support**: Enhanced support for Ollama, OpenAI, Qwen, Anthropic
- âœ… **LangGraph Studio**: Visual workflow debugging and development
- âœ… **Improved Retry Logic**: Critic-based evaluation with automatic retry/escalation