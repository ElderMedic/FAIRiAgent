# FAIRiAgent Environment Configuration
# Copy this file to .env and fill in your actual values

# LangSmith tracing. Off by default; set LANGSMITH_API_KEY to enable.
# To disable when key is set: LANGSMITH_DISABLE=1 or LANGCHAIN_TRACING_V2=false
# LANGSMITH_API_KEY=
# LANGSMITH_PROJECT=fairifier
# LANGSMITH_USE_FAIR_NAMING=true
# LANGSMITH_ENDPOINT=https://api.smith.langchain.com

# LLM Configuration (Optional - defaults to Ollama)
# Supported providers: ollama, openai, qwen, anthropic (claude)
LLM_PROVIDER=ollama
FAIRIFIER_LLM_MODEL=qwen3:30b-a3b
FAIRIFIER_LLM_BASE_URL=http://localhost:11434

# API Keys (Required for OpenAI, Qwen, or Anthropic)
# For OpenAI: Get your API key from https://platform.openai.com/api-keys
# For Qwen: Get your API key from https://dashscope.console.aliyun.com/
# For Anthropic: Get your API key from https://console.anthropic.com/
LLM_API_KEY=your_api_key_here

# Custom API Base URLs (Optional - uses defaults if not set)
# For OpenAI: defaults to https://api.openai.com/v1
# OPENAI_API_BASE_URL=https://api.openai.com/v1
# QWEN_API_BASE_URL=https://dashscope-intl.aliyuncs.com/compatible-mode/v1

# LLM Parameters (Optional)
LLM_TEMPERATURE=0.5
LLM_MAX_TOKENS=100000
# Enable thinking mode (requires streaming for some models)
# Set to true/1/yes to enable thinking mode
LLM_ENABLE_THINKING=false

# Document Parsing Context Limits (Optional)
# Modern LLMs support 200K+ tokens (~800K chars)
# Defaults are conservative: 600K for Markdown, 500K for text
# Increase if your LLM supports larger context windows
# MAX_DOC_CONTEXT_MARKDOWN=600000  # For MinerU Markdown (~150K tokens)
# MAX_DOC_CONTEXT_TEXT=500000       # For raw text/PDF (~125K tokens)

# External Services (Optional)
QDRANT_URL=http://localhost:6333

# FAIR-DS API Configuration
# Swagger UI: http://localhost:8083/swagger-ui/index.html
# Available endpoints: /api/package, /api/terms, /api/upload
FAIR_DS_API_URL=http://localhost:8083

# Processing Configuration
FAIRIFIER_MAX_DOCUMENT_SIZE_MB=50
FAIRIFIER_MAX_PROCESSING_TIME_MINUTES=10
FAIRIFIER_MIN_CONFIDENCE_THRESHOLD=0.75

# Retry Configuration (Optional)
# Maximum retries per step before escalation
FAIRIFIER_MAX_STEP_RETRIES=2
# Maximum total retries across all steps in a workflow
FAIRIFIER_MAX_GLOBAL_RETRIES=5

# Critic Decision Thresholds (Optional)
# ACCEPT threshold for DocumentParser (default: 0.75)
FAIRIFIER_CRITIC_ACCEPT_THRESHOLD_DOCUMENT_PARSER=0.75
# ACCEPT threshold for KnowledgeRetriever (default: 0.7)
FAIRIFIER_CRITIC_ACCEPT_THRESHOLD_KNOWLEDGE_RETRIEVER=0.7
# ACCEPT threshold for JSONGenerator (default: 0.75)
FAIRIFIER_CRITIC_ACCEPT_THRESHOLD_JSON_GENERATOR=0.75
# General ACCEPT threshold for LLM evaluation (default: 0.7)
FAIRIFIER_CRITIC_ACCEPT_THRESHOLD_GENERAL=0.7
# Minimum score for RETRY (below this is ESCALATE, default: 0.4)
FAIRIFIER_CRITIC_RETRY_MIN_THRESHOLD=0.4
# Maximum score for RETRY (above this is ACCEPT, default: 0.69)
FAIRIFIER_CRITIC_RETRY_MAX_THRESHOLD=0.69

# MinerU Document Conversion (Optional)
# Enable MinerU for enhanced PDF to Markdown conversion with structure preservation
# Requires MinerU HTTP server running (see: https://github.com/opendatalab/MinerU)
MINERU_ENABLED=true
# MinerU HTTP server URL (default: http://localhost:30000)
MINERU_SERVER_URL=http://localhost:30000
# MinerU CLI command path (default: mineru)
MINERU_CLI_PATH=mineru
# Backend type (default: vlm-http-client for HTTP server)
MINERU_BACKEND=vlm-http-client
# Conversion timeout in seconds (default: 300)
MINERU_TIMEOUT_SECONDS=300

# Checkpointer Configuration (Optional)
# Controls workflow state persistence for resume/interrupt support
# Options: none (stateless), memory (dev/test only), sqlite (production)
# Default: sqlite
CHECKPOINTER_BACKEND=sqlite
# SQLite database path for checkpoints (only used when backend=sqlite)
# Default: output/.checkpoints.db
# CHECKPOINT_DB_PATH=output/.checkpoints.db